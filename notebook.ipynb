{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the raw data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "df = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "# add the negative examples\n",
    "with open('data/negative.txt', 'r', encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        df = df.append({'text': line, 'label': 'huh'}, ignore_index=True)\n",
    "\n",
    "# add the positive examples\n",
    "with open('data/positive.txt', 'r', encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        df = df.append({'text': line, 'label': 'twss'}, ignore_index=True)\n",
    "\n",
    "# shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label  \\\n",
      "0  if we do not believe in free expression for pe...   huh   \n",
      "1  if you wind up with a boring, miserable life b...   huh   \n",
      "2  do not you think these buns are a little too b...  twss   \n",
      "3                     hey look it fits in the crack!  twss   \n",
      "4  america stands strongest in challenging terror...   huh   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [if, we, do, not, believe, in, free, expressio...   \n",
      "1  [if, you, wind, up, with, a, boring, ,, misera...   \n",
      "2  [do, not, you, think, these, bun, are, a, litt...   \n",
      "3            [hey, look, it, fit, in, the, crack, !]   \n",
      "4  [america, stand, strongest, in, challenging, t...   \n",
      "\n",
      "                                             cleaned  \n",
      "0  if we do not believe in free expression for pe...  \n",
      "1  if you wind up with a boring , miserable life ...  \n",
      "2  do not you think these bun are a little too bi...  \n",
      "3                     hey look it fit in the crack !  \n",
      "4  america stand strongest in challenging terrori...  \n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "\n",
    "# Lowercase all words, remove contractions and whitespace\n",
    "df['text'] = df['text'].apply(lambda x: contractions.fix(x.lower()).strip())\n",
    "\n",
    "# tokenize\n",
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# create lemmatizer\n",
    "l = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [l.lemmatize(word) for word in x])\n",
    "\n",
    "# clean words\n",
    "df['cleaned'] = df['tokens'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts\n",
    "texts = df['cleaned'].values\n",
    "\n",
    "# gets labels\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses label encoder to encode labels. Convert to 0/1\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "df['encoded'] = encoded_labels\n",
    "\n",
    "encoder_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "\n",
    "encoded_texts = df['encoded'].values\n",
    "\n",
    "# split 80/20 - train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\Desktop\\edu\\sem-5\\natural-language-processing\\project\\.env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Uses Count vectorizer to get frequency of the words\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "\n",
    "# encodes all training sentences\n",
    "sents_encoded = vectorizer.fit_transform(X_train)\n",
    "\n",
    "counts = sents_encoded.sum(axis=0).A1\n",
    "vocab = list(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero():\n",
    "    return 0\n",
    "\n",
    "# Builds the model.\n",
    "# Uses laplace smoothing for words in test set not present in vocab of train set\n",
    "class NaiveBayes:\n",
    "\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def group_by_class(self, X, y):\n",
    "        data = dict()\n",
    "        for c in self.classes:\n",
    "            data[c] = X[np.where(y == c)]\n",
    "        return data\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_class_items = {}\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = vocab\n",
    "\n",
    "        n = len(X)\n",
    "\n",
    "        grouped_data = self.group_by_class(X, y)\n",
    "\n",
    "        for c, data in grouped_data.items():\n",
    "            self.n_class_items[c] = len(data)\n",
    "            # taking log for easier calculation\n",
    "            self.log_class_priors[c] = math.log(self.n_class_items[c] / n)\n",
    "            self.word_counts[c] = defaultdict(zero)\n",
    "\n",
    "            for text in data:\n",
    "                counts = Counter(word_tokenize(text))\n",
    "                for word, count in counts.items():\n",
    "                    self.word_counts[c][word] += count\n",
    "\n",
    "        return self\n",
    "\n",
    "    def laplace_smoothing(self, word, text_class):\n",
    "        num = self.word_counts[text_class][word] + 1\n",
    "        denom = self.n_class_items[text_class] + len(self.vocab)\n",
    "        return math.log(num / denom)\n",
    "\n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for text in X:\n",
    "\n",
    "            class_scores = {c: self.log_class_priors[c] for c in self.classes}\n",
    "\n",
    "            words = set(word_tokenize(text))\n",
    "            for word in words:\n",
    "                if word not in self.vocab:\n",
    "                    continue\n",
    "\n",
    "                for c in self.classes:\n",
    "\n",
    "                    log_w_given_c = self.laplace_smoothing(word, c)\n",
    "                    class_scores[c] += log_w_given_c\n",
    "\n",
    "            result.append(max(class_scores, key=class_scores.get))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 83.07%\n"
     ]
    }
   ],
   "source": [
    "# instantiate the naive bayes classifier\n",
    "naive_bayes = NaiveBayes(classes=np.unique(labels)).fit(X_train, y_train)\n",
    "\n",
    "# Tests the model on test set and reports the Accuracy\n",
    "predicted_labels = naive_bayes.predict(X_test)\n",
    "\n",
    "naive_bayes_accuracy = 100 * accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "print(\"Naive Bayes Accuracy: {:.2f}%\".format(naive_bayes_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twss', 'huh', 'huh']\n"
     ]
    }
   ],
   "source": [
    "# texts on which we need to predict\n",
    "sentences = [\"That was big\", \"I am loving it\", \"I like chinese noodles\"]\n",
    "\n",
    "# Gets probabilities\n",
    "prediction = naive_bayes.predict(sentences)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "oov_tok = '<OOK>'\n",
    "embedding_dim = 100\n",
    "max_length = 150\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "# tokenizes sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# vocabulary size\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# converts train dataset to sequence and pads sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "y_train_encoded = np.fromiter(map(lambda x: 0 if x == 'huh' else 1, y_train), dtype=np.int32)\n",
    "\n",
    "# converts Test dataset to sequence and pads sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 150, 100)          895700    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 128)              84480     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 983,301\n",
      "Trainable params: 983,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compiles model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "141/141 [==============================] - 41s 271ms/step - loss: 0.3230 - accuracy: 0.8572 - val_loss: 0.1568 - val_accuracy: 0.9478\n",
      "Epoch 2/5\n",
      "141/141 [==============================] - 34s 242ms/step - loss: 0.1027 - accuracy: 0.9614 - val_loss: 0.1304 - val_accuracy: 0.9538\n",
      "Epoch 3/5\n",
      "141/141 [==============================] - 45s 321ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.1235 - val_accuracy: 0.9498\n",
      "Epoch 4/5\n",
      "141/141 [==============================] - 60s 425ms/step - loss: 0.0772 - accuracy: 0.9739 - val_loss: 0.1405 - val_accuracy: 0.9558\n",
      "Epoch 5/5\n",
      "141/141 [==============================] - 39s 278ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.1440 - val_accuracy: 0.9498\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(train_padded, y_train_encoded, epochs=5, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the LSTM Network is 94.06%\n"
     ]
    }
   ],
   "source": [
    "# Gets probabilities\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "# Gets labels based on probability 1 if p>= 0.5 else 0\n",
    "for each in prediction:\n",
    "    if each[0] >= 0.5:\n",
    "        each[0] = 1\n",
    "    else:\n",
    "        each[0] = 0\n",
    "prediction = prediction.astype('int32')\n",
    "\n",
    "y_test_encoded = np.fromiter(map(lambda x: 0 if x == 'huh' else 1, y_test), dtype=np.int32)\n",
    "\n",
    "lstm_accuracy = 100 * accuracy_score(y_test_encoded, prediction)\n",
    "\n",
    "# Calculates accuracy on Test data\n",
    "print(\"The accuracy of the LSTM Network is {:.2f}%\".format(lstm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7249748]\n",
      "[0.590703]\n",
      "[0.29367533]\n",
      "['twss', 'twss', 'huh']\n"
     ]
    }
   ],
   "source": [
    "# texts on which we need to predict\n",
    "sentence = [\"That's big\", \"I am loving it\", \"I like chinese noodles\"]\n",
    "\n",
    "# converts to a sequence\n",
    "test_sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "# pads the sequence\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "# Gets probabilities\n",
    "prediction = model.predict(test_padded)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Gets labels based on probability 1 if p >= 0.5 else 0\n",
    "for each in prediction:\n",
    "    print(each)\n",
    "    if each[0] >= 0.5:\n",
    "        results.append('twss')\n",
    "    else:\n",
    "        results.append('huh')\n",
    "        \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Network is better than Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "if lstm_accuracy > naive_bayes_accuracy:\n",
    "    print(\"LSTM Network is better than Naive Bayes\")\n",
    "else:\n",
    "    print(\"Naive Bayes is better than LSTM Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: last_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: last_model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F3D45E2460> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F3B47E1730> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('last_model')\n",
    "\n",
    "# save tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f544fd1e872d1f1de87a931a3e9fbca7eb693bef23fa7e3a3f4305021f6da3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
